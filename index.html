<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jianxiang Feng (Under Construction)</title>
  
  <meta name="author" content="Jianxiang Feng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/favicon.ico">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jianxiang Feng</name>
              </p>
              <p>I am a PhD student at the <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-8017/">Institute of Robotic and Mechtronic</a>, <a href="https://www.dlr.de/en/">DLR</a> and <a href="https://www.tum.de/en">TU Munich</a>. Based in Department of Perception and Cognition (PEK), RM, DLR, I am advised by Prof. <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/"> Rudolph Triebel</a> (DLR) and affiliated with <a href="https://www.mu-ds.de/"> Munich School of Data Science </a>.
              </p>
              <p>
                My research aims to equip robots with introspective capabilities, i.e., the awareness of its own status in terms of various aspects scuh as limitation of its knowledge and abilities. More concretely, I am passionate about leveraging probabilitistic machine learning methods such as Bayesian Neural Networks, Probabilistic Graphical Models, Normalizing Flows for robotic relevant tasks, e.g. Uncertainty estimation, Active Learning, Out-of-distribution detection, Assembly Sequence Planning and Feasibility Prediction. 
              </p>
              <p style="text-align:center">
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://github.com/JianxiangFENG">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=b-5CscIAAAAJ&hl=en">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://www.linkedin.com/in/jianxiangfeng/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://twitter.com/fengjianxiang?lang=en">Twitter</a>
                <br><br>
                jianxiang.feng at dlr dot de
                <br><br>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile-half.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
            - A workshop <a href="https://openreview.net/forum?id=Zw9rQMDl8m&referrer=[the%20profile%20of%20Jianxiang%20Feng]">paper</a> of Robotics and AI: The Future of Industrial Assembly Tasks at RSS 2023 got accepted.
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Highlights</heading>
              <!-- <p>
                I'm interested in working on the intersection of computer vision, machine learning and robotics.
              </p> -->

            <!-- <div class="list-item highlight previews" data-category="highlight"> -->

              <h4> CYBATHLON Challenges (assistant robot race)</h4>
              <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/EoER_5vYZsU?&autoplay=0" title="YouTube video player" frameborder="0" allow="accelerometer; allow='autoplay'; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </a>  
              
              <h4> Bayesian Active Learning Demo on an assitive robot EDAN</h4>
              <a href="https://arxiv.org/pdf/2109.11547">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/kfWNEBbvuSE?&autoplay=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	      </a> 
              
<!-- 	      <h4> Bayesian Active Learning Demo on an assitive robot EDAN</h4>
              <a href="https://arxiv.org/pdf/2109.11547"><video width="560" height="315" playsinline="" muted="" autoplay="" loop=""><source src="images/bal_edan.mp4" type="video/mp4"></video></a> -->
              
              <h4> Bayesian Active Learning Demo on aerial manipulation robnot SAM</h4>
              <a href="https://www.youtube.com/watch?v=JRnPIARW8xY&ab_channel=DLRRM">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/JRnPIARW8xY?&autoplay=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </a>

              <!-- <a href="https://arxiv.org/pdf/2109.11547"><video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/bal_edan.mp4" type="video/mp4"></video></a> -->
            <!-- </div> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Preprints</heading>
              <br>(*: equal contribution.)
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <! ------------------------------------------------------- NF RASP ----------------------------------------------------------------- -->
             <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <img src='GRACE_teaser.pdf' width="160" height="2100px" > -->
                    <embed src="images/NFs_ASP_teaser.pdf" width="190" />
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=Zw9rQMDl8m&referrer=[the%20profile%20of%20Jianxiang%20Feng]">
                    <papertitle>Density-based Feasibility Learning with
                      Normalizing Flows for Introspective Robotic
                      Assembly</papertitle>
                  </a>
                  <br>
                  <strong>Jianxiang Feng*</strong>,
                  Matan Atad*,
                  <a href="https://scholar.google.com.uy/citations?user=NeZae4kAAAAJ&hl=es">Ismael Rodríguez</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
                  <br>
                  submitted to the Workshop on Robotics and AI: The Future of Industrial Assembly Tasks,
                  Robotics: Science and Systems (RSS), 2023.
                  <br>
                  <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a> -->
                  code (to be released.)
                  /
                  <!-- <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a> / -->
                  <a href="https://openreview.net/forum?id=Zw9rQMDl8m&referrer=[the%20profile%20of%20Jianxiang%20Feng]">Preprint</a>
                  <!-- / -->
                  <!-- <a href="data/bal2022.bib">bibtex</a> -->
                  <p></p>
                  <p>
                    A density-based method with normalizing flows for feasibility learning in Robotic Assembly based on only feasible examples.
                  </p>
              </tr>
          <! ----------------------------------------------------------------------------------------------------------------------------- -->	
          <! ------------------------------------------------------- RASP ----------------------------------------------------------------- -->
             <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <embed src="images/GRACE_teaser.pdf" width="190" />
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2303.10135.pdf">
                    <papertitle>Efficient and Feasible Robotic Assembly Sequence Planning via
                      Graph Representation Learning</papertitle>
                  </a>
                  <br>
                  Matan Atad*,
                  <strong>Jianxiang Feng*</strong>,
                  <a href="https://scholar.google.com.uy/citations?user=NeZae4kAAAAJ&hl=es">Ismael Rodríguez</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
                  <br>
                  submitted to 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
                  <br>
                  <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a> -->
                  code (to be released.)
                  /
                  <!-- <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a> / -->
                  <a href="https://arxiv.org/pdf/2303.10135">arXiv</a>
                  <!-- / -->
                  <!-- <a href="data/bal2022.bib">bibtex</a> -->
                  <p></p>
                  <p>
                  A holistic graphical approach including a graph representation for product assemblies and a policy architecture, Graph Assembly Processing Network, dubbed GRACE to predict assembly sequences in a step-by-step manner.
                  </p>
              </tr>
          <! ----------------------------------------------------------------------------------------------------------------------------- -->	
          
  <! ------------------------------------------------------- survey ----------------------------------------------------------------- -->
  <!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <embed src="images/survey.pdf" width="190" />
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2107.03342">
            <papertitle>A Survey of Uncertainty in Deep Neural Networks </papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=JSDN9rsAAAAJ&hl=en">Jakob Gawlikowski</a>,
          Cedrique Rovile Njieutcheu Tassi, 
          Mohsin Ali, 
          <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
          <a href="https://www.hummat.com/">Matthias Humt</a>,
          <strong>Jianxiang Feng</strong>,
          Anna Kruspe, 
          <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
          Peter Jung, 
          Ribana Roscher, 
          Muhammad Shahzad, 
          Wen Yang, 
          Richard Bamler, 
          <a href="https://www.professoren.tum.de/en/zhu-xiaoxiang"> Xiaoxiang Zhu</a>
          <br>
          <!-- International Conference on Machine Learning, 2020. -->
          <br>
          <!-- <a href="https://github.com/DLR-RM/curvature">code</a>
          / -->
          <!-- <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
          / -->
          <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
          / -->
          <!-- <a href="data/pmlr-v119-lee20b.bib">bibtex</a> -->
          <p></p>
          <p>
           A comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities.. 
          </p>
      </tr>
  <! ----------------------------------------------------------------------------------------------------------------------------- -->	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
            <br>(*: equal contribution.)
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<! ------------------------------------------------------- BAL EDAN ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='bal_edan_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bal_edan.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/iros22_bal.png' width="190">
        </div>
        <script type="text/javascript">
          function bal_edan_start() {
            document.getElementById('bal_edan_image').style.opacity = "1";
          }

          function bal_edan_stop() {
            document.getElementById('bal_edan_image').style.opacity = "0";
          }
          bal_edan_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2109.11547">
          <papertitle>Bayesian Active Learning for Sim-to-Real Robotic Perception</papertitle>
        </a>
        <br>
        <strong>Jianxiang Feng</strong>,
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
        <br>
        <a href="https://github.com/DLR-RM/BayesSim2Real">code</a>
        /
        <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a>
        /
        <a href="https://arxiv.org/pdf/2109.11547">arXiv</a>
        /
        <a href="data/bal2022.bib">bibtex</a>
        <p></p>
        <p>
          Efficient acquisition of real data within a Sim-to-Real learning pipeline via deep Bayesian active learning to minimize manual annotation efforts.
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- ISRR ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/isrr_teaser.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-95459-8_40">
          <papertitle>Bayesian Active Learning for Sim-to-Real Robotic Perception</papertitle>
        </a>
        <br>
        <strong>Jianxiang Feng*</strong>,
        <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner*</a>,
        <a href="https://scholar.google.com/citations?user=VGBlCk4AAAAJ&hl=en">Zoltán-Csaba Márton</a>,
        <a href="https://ai.uni-bremen.de/team/ferenc_balint-benczedi">Ferenc Bálint-Benczédi</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        The International Symposium of Robotics Research (ISRR) 2019.
        <br>
        <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a>
        /
        <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a>
        / -->
        <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        /
        <a href="data/isrr19.bib">bibtex</a>
        <p></p>
        <p>
        We show a performance increase using more reliable uncertainty estimates from Bayesian Neural Networks as unary potentials within a Conditional Random Field (CRF), which is able to incorporate contextual information as well.
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- CoRL21 ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/corl21.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v164/lee22c.html">
          <papertitle>Trust Your Robots! Predictive Uncertainty Estimation of Neural Networks with Sparse Gaussian Processes</papertitle>
        </a>
        <br>
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <strong>Jianxiang Feng</strong>,
        <a href="https://www.hummat.com/">Matthias Humt</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/marcus.mueller/">Marcus G. Muller</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        5th Conference on Robot Learning (CoRL) 2021
        <br>
        <a href="https://github.com/DLR-RM/moegplib">code</a>
        /
        <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
        /
        <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        / -->
        <a href="data/pmlr-v164-lee22c.bib">bibtex</a>
        <p></p>
        <p>
        A probabilistic framework to obtain both reliable and fast uncertainty estimates for predictions with Deep Neural Networks (DNNs) based on Sparse Gaussian Processes. 
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- ICML2020 ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/icml20.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="http://proceedings.mlr.press/v119/lee20b.html">
          <papertitle>Estimating Model Uncertainty of Neural Networks in Sparse Information Form  </papertitle>
        </a>
        <br>
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <a href="https://www.hummat.com/">Matthias Humt</a>,
        <strong>Jianxiang Feng</strong>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        International Conference on Machine Learning, 2020.
        <br>
        <a href="https://github.com/DLR-RM/curvature">code</a>
        /
        <!-- <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
        / -->
        <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        / -->
        <a href="data/pmlr-v119-lee20b.bib">bibtex</a>
        <p></p>
        <p>
        A probabilistic framework to obtain both reliable and fast uncertainty estimates for predictions with Deep Neural Networks (DNNs) based on Sparse Gaussian Processes. 
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- SAM ----------------------------------------------------------------- -->
<!--    <tr onmouseout="FR_SAM_stop()" onmouseover="FR_SAM_start()"  bgcolor="#ffffd0"> -->
  <tr onmouseout="FR_SAM_stop()" onmouseover="FR_SAM_start()" >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='FR_SAM_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bal_edan.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/FR2023.png' width="190">
        </div>
        <script type="text/javascript">
          function FR_SAM_start() {
            document.getElementById('FR_SAM_image').style.opacity = "1";
          }

          function FR_SAM_stop() {
            document.getElementById('FR_SAM_image').style.opacity = "0";
          }
          FR_SAM_stop()
        </script>
      </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://elib.dlr.de/194517/1/Vol3_10.pdf">
        <papertitle>Virtual Reality via Object Pose Estimation and Active Learning: Realizing Telepresence Robots with Aerial Manipulation Capabilities</papertitle>
      </a>
      <br>
      <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>, <a href="https://rmc.dlr.de/rm/en/staff/ribin.balachandran/">Ribin Radhakrishna Balachandran</a> , Konstantin Kondak, Andre Coelho, Marco De Stefano, Matthias Humt, <strong>Jianxiang Feng</strong>, Tamim Asfour,   <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
    
      <br>
      Field Robotics
      <br>
      <a href="https://www.youtube.com/watch?v=JRnPIARW8xY&ab_channel=DLRRM">video</a>
      <!-- /
      <a href="data/bal2022.bib">bibtex</a> -->
      <p></p>
      <p>
        A novel teleoperation system for advancing aerial manipulation in dynamic and unstructured environments based on pose estimation pipelines for the industrial objects of
        both known and unknown geometries and an active learning pipeline.
      </p>
    </td>
  </tr>
  <! ------------------------------------------------------------------------------------------------------------------------ -->		
  </tbody></table>

				
	<! ------------------------------------------------------- Misc ---------------------------------------------------------- -->	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		
		
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td> -->
            <td width="75%" valign="center">
              Master Thesis: <a href="https://elib.dlr.de/194212/">"Graph Neural Networks for Knowledge Transfer in Robotic Assembly Sequence Planning"</a> by Matan Atad, co-supervision with <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>, <a href="https://rmc.dlr.de/rm/en/staff/ismael.rodriguezbrena/index.html">Ismael Rodriguezbrena</a>>.
              <br>
              <br>
              Master Thesis: <a href="https://elib.dlr.de/194212/">"Scene Graph Generation from Visual perception for Task and Motion Planning"</a> by Mohit Kumar, co-supervision with <a href="https://rmc.dlr.de/rm/en/staff/samuel.bustamante/">Samuel Bustamante</a>.
              </td>
          </tr>
	<! ------------------------------------------------------------------------------------------------------------------------ -->				
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Link to the template</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
