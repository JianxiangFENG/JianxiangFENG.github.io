<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jianxiang Feng</title>
  
  <meta name="author" content="Jianxiang Feng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/favicon.ico">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jianxiang Feng</name>
              </p>
              <p>I am a PhD student at the <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-8017/">Institute of Robotic and Mechtronic</a>, <a href="https://www.dlr.de/en/">DLR</a> and <a href="https://www.tum.de/en">TU Munich</a>. Working in the Department of Perception and Cognition (PEK), RM, DLR, I am advised by Prof. <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/"> Rudolph Triebel</a> (DLR) and affiliated with <a href="https://www.mu-ds.de/"> Munich School of Data Science </a>.
              </p>
              <p>
                My research aims to equip robots with introspective capabilities, i.e., the awareness of its own status in terms of various aspects scuh as limitation of its knowledge and abilities. More concretely, I am passionate about leveraging probabilitistic machine learning methods such as Bayesian Neural Networks, Probabilistic Graphical Models, Normalizing Flows for robotic relevant tasks, e.g. Uncertainty estimation, Active Learning, Out-of-distribution detection, Assembly Sequence Planning and Feasibility Prediction. 
              </p>
              <div id="more-bio" style="display: None">
                <p>Jianxiang Feng received his bachelor degree in electronic engineering from Beijing University of Posts and Telecommunication (BUPT), China (2011-2015) and his master degree in electronic and information technology from Technical University of Munich (TUM), Germany (2016-2019). Since August 2019, he is a research scientist at the Institute of Robotics and Mechatronics (RM), the German Aerospace Center (DLR), Germany. His research interests reside in the intersection of robotics and machine learning.</p>
              </div>
              <p style="text-align:center">
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="javascript:toggle_bio()">Formal Bio</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://github.com/JianxiangFENG">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=b-5CscIAAAAJ&hl=en">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://www.linkedin.com/in/jianxiangfeng/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://twitter.com/fengjianxiang?lang=en">Twitter</a>
                <br><br>
                jianxiang.feng at dlr dot de
                <br><br>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile-half.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <div class="list-item highlight" data-category="highlight">
              <p class="date">06.2023</p> &nbsp;&nbsp;&nbsp; A paper of <a href="https://sites.google.com/nvidia.com/industrial-assembly">workshop</a> on Robotics and AI: The Future of Industrial Assembly Tasks at RSS 2023 got accepted.
              </div><div class="list-item highlight" data-category="highlight">

	    <div class="list-item highlight" data-category="highlight">
		 <p class="date">03.2023</p> &nbsp;&nbsp;&nbsp; Won the 1st place in the discipline assist robot race of <a href="https://cybathlon.ethz.ch/de/teams/edan">Cybathlon Challenge</a> as part of EDAN team. <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-3755/17612_read-81519/year-2023/">press</a>
            </div>
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Video Highlights</heading>
            <p>
              <h4> &emsp;&emsp;&emsp;&emsp; <a href="https://cybathlon.ethz.ch/de/teams/edan">Cybathlon Challenges </a> (assistant robot race) 
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  Bayesian Active Learning Demo on <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11670/20388_read-47709/">EDAN</a>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Bayesian Active Learning Demo on <a href="https://www.youtube.com/watch?v=ZoNNjQfUdJw&ab_channel=DLRRM">SAM</a></h4>
              </p>
            <div class="list-item highlight previews" data-category="highlight">
              <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM"><iframe width="350" height="250" src="https://www.youtube.com/embed/EoER_5vYZsU?&autoplay=1&loop=1&playlist=EoER_5vYZsU&mute=1&start=100&showinfo=0" title="YouTube video player" frameborder="0" allow="accelerometer; allow='autoplay'; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </a>  
              <!-- <h4> CYBATHLON Challenges (assistant robot race)</h4> -->
              
              <!-- <h4> Bayesian Active Learning Demo on an assitive robot EDAN</h4> -->
              <a href="https://arxiv.org/pdf/2109.11547"><iframe width="350" height="250" src="https://www.youtube.com/embed/kfWNEBbvuSE?&autoplay=1&loop=1&playlist=kfWNEBbvuSE&mute=1&start=31&showinfo=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	          </a> 
              
             <!--  <h4> Bayesian Active Learning Demo on an assitive robot EDAN</h4>
              <a href="https://arxiv.org/pdf/2109.11547"><video width="560" height="315" playsinline="" muted="" autoplay="" loop=""><source src="images/bal_edan.mp4" type="video/mp4"></video></a> -->
              
              <!-- <h4> Bayesian Active Learning Demo on aerial manipulation robnot SAM</h4> -->
              <a href="https://www.youtube.com/watch?v=JRnPIARW8xY&ab_channel=DLRRM"><iframe width="350" height="250" src="https://www.youtube.com/embed/JRnPIARW8xY?&autoplay=1&loop=1&playlist=JRnPIARW8xY&mute=1&start=215&showinfo=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </a>
            </div>
            <div class="grid"></div>
            <!-- <div class="list-item highlight previews" data-category="highlight">
              <h4> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://cybathlon.ethz.ch/de/teams/edan">Cybathlon Challenges </a> (assistant robot race)</h4>
              <h4> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Bayesian Active Learning Demo on <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-11670/20388_read-47709/">EDAN</h4></a>
              <h4> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Bayesian Active Learning Demo on <a href="https://www.youtube.com/watch?v=ZoNNjQfUdJw&ab_channel=DLRRM">SAM</a></h4>
            </div> -->
          <!-- </p> -->
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <!-- </tbody> -->
        <!-- </table> -->
        </td>
      </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Preprints</heading>
              <br>(*: equal contribution.)
            </td>
          </tr>
        </tbody>
      </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <! ------------------------------------------------------- RASP ----------------------------------------------------------------- -->
             <tr >
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <embed src="images/GRACE_teaser.pdf" width="190" />
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2303.10135.pdf">
                    <papertitle>Efficient and Feasible Robotic Assembly Sequence Planning via
                      Graph Representation Learning</papertitle>
                  </a>
                  <br>
                  Matan Atad*,
                  <strong>Jianxiang Feng*</strong>,
                  <a href="https://scholar.google.com.uy/citations?user=NeZae4kAAAAJ&hl=es">Ismael Rodríguez</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
                  <br>
                  submitted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023.
                  <br>
                  <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a> -->
                  code (to be released.)
                  /
                  <!-- <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a> / -->
                  <a href="https://arxiv.org/pdf/2303.10135">arXiv</a>
                  <!-- / -->
                  <!-- <a href="data/bal2022.bib">bibtex</a> -->
                  <p></p>
                  <p>
                  A holistic graphical approach including a graph representation for product assemblies and a policy architecture, Graph Assembly Processing Network, dubbed GRACE to predict assembly sequences in a step-by-step manner.
                  </p>
              </tr>
          <! ----------------------------------------------------------------------------------------------------------------------------- -->	
          
  <! ------------------------------------------------------- survey ----------------------------------------------------------------- -->
  <!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
     <tr >
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <embed src="images/survey1.pdf" width="190" />
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2107.03342">
            <papertitle>A Survey of Uncertainty in Deep Neural Networks </papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=JSDN9rsAAAAJ&hl=en">Jakob Gawlikowski</a>,
          Cedrique Rovile Njieutcheu Tassi, 
          Mohsin Ali, 
          <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
          <a href="https://www.hummat.com/">Matthias Humt</a>,
          <strong>Jianxiang Feng</strong>,
          Anna Kruspe, 
          <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
          Peter Jung, 
          Ribana Roscher, 
          Muhammad Shahzad, 
          Wen Yang, 
          Richard Bamler, 
          <a href="https://www.professoren.tum.de/en/zhu-xiaoxiang"> Xiaoxiang Zhu</a>
          <br>
          <!-- International Conference on Machine Learning, 2020. -->
          <br>
          <!-- <a href="https://github.com/DLR-RM/curvature">code</a>
          / -->
          <!-- <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
          / -->
          <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
          / -->
          <!-- <a href="data/pmlr-v119-lee20b.bib">bibtex</a> -->
          <p></p>
          <p>
           A comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. 
          </p>
      </tr>
  <! ----------------------------------------------------------------------------------------------------------------------------- -->	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
            <br>(*: equal contribution.)
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <! ------------------------------------------------------- NF RASP ----------------------------------------------------------------- -->
             <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <img src='GRACE_teaser.pdf' width="160" height="2100px" > -->
                    <embed src="images/NFs_ASP_teaser.pdf" width="190" />
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=Zw9rQMDl8m&referrer=[the%20profile%20of%20Jianxiang%20Feng]">
                    <papertitle>Density-based Feasibility Learning with
                      Normalizing Flows for Introspective Robotic
                      Assembly</papertitle>
                  </a>
                  <br>
                  <strong>Jianxiang Feng*</strong>,
                  Matan Atad*,
                  <a href="https://scholar.google.com.uy/citations?user=NeZae4kAAAAJ&hl=es">Ismael Rodríguez</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
                  <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
                  <br>
                  Workshop on Robotics and AI: The Future of Industrial Assembly Tasks,
                  Robotics: Science and Systems (RSS) 2023.
                  <br>
                  <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a> -->
                  code (to be released.)
                  /
                  <!-- <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a> / -->
                  <a href="https://openreview.net/forum?id=Zw9rQMDl8m&referrer=[the%20profile%20of%20Jianxiang%20Feng]">Preprint</a>
                  <!-- / -->
                  <!-- <a href="data/bal2022.bib">bibtex</a> -->
                  <p></p>
                  <p>
                    A density-based method with normalizing flows for feasibility learning in Robotic Assembly based on only feasible examples.
                  </p>
              </tr>
          <! ----------------------------------------------------------------------------------------------------------------------------- -->	
<! ------------------------------------------------------- BAL EDAN ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr  >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='bal_edan_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bal_edan.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/iros22_bal.png' width="190">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2109.11547">
          <papertitle>Bayesian Active Learning for Sim-to-Real Robotic Perception</papertitle>
        </a>
        <br>
        <strong>Jianxiang Feng</strong>,
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022.
        <br>
        <a href="https://github.com/DLR-RM/BayesSim2Real">code</a>
        /
        <a href="https://arxiv.org/pdf/2109.11547">arXiv</a>
        /
        <a href="data/iros2022_bayesSim2real_v2.pdf">slides</a>
        /
        <a href="data/IROS22_1546.mp4">video</a>
        /
        <a href="data/bal2022.bib">bibtex</a>
        <p></p>
        <p>
          Efficient acquisition of real data within a Sim-to-Real learning pipeline via deep Bayesian active learning to minimize manual annotation efforts.
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- ISRR ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/isrr_teaser.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-95459-8_40">
          <papertitle>Bayesian Active Learning for Sim-to-Real Robotic Perception</papertitle>
        </a>
        <br>
        <strong>Jianxiang Feng*</strong>,
        <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner*</a>,
        <a href="https://scholar.google.com/citations?user=VGBlCk4AAAAJ&hl=en">Zoltán-Csaba Márton</a>,
        <a href="https://ai.uni-bremen.de/team/ferenc_balint-benczedi">Ferenc Bálint-Benczédi</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        The International Symposium of Robotics Research (ISRR) 2019.
        <br>
        <!-- <a href="https://github.com/DLR-RM/BayesSim2Real">code</a>
        /
        <a href="https://www.youtube.com/watch?v=EoER_5vYZsU&t=3s&ab_channel=DLRRM">video</a>
        / -->
        <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        /
        <a href="data/isrr19.bib">bibtex</a>
        <p></p>
        <p>
        We show a performance increase using more reliable uncertainty estimates from Bayesian Neural Networks as unary potentials within a Conditional Random Field (CRF), which is able to incorporate contextual information as well.
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- CoRL21 ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/corl21.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v164/lee22c.html">
          <papertitle>Trust Your Robots! Predictive Uncertainty Estimation of Neural Networks with Sparse Gaussian Processes</papertitle>
        </a>
        <br>
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <strong>Jianxiang Feng</strong>,
        <a href="https://www.hummat.com/">Matthias Humt</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/marcus.mueller/">Marcus G. Muller</a>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        5th Conference on Robot Learning (CoRL) 2021.
        <br>
        <a href="https://github.com/DLR-RM/moegplib">code</a>
        /
        <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
        /
        <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        / -->
        <a href="data/pmlr-v164-lee22c.bib">bibtex</a>
        <p></p>
        <p>
        A probabilistic framework to obtain both reliable and fast uncertainty estimates for predictions with Deep Neural Networks (DNNs) based on Sparse Gaussian Processes. 
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- ICML2020 ----------------------------------------------------------------- -->
<!--     <tr onmouseout="bal_edan_stop()" onmouseover="bal_edan_start()"  bgcolor="#ffffd0"> -->
   <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <embed src="images/icml20.pdf" width="190" />
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="http://proceedings.mlr.press/v119/lee20b.html">
          <papertitle>Estimating Model Uncertainty of Neural Networks in Sparse Information Form  </papertitle>
        </a>
        <br>
        <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>,
        <a href="https://www.hummat.com/">Matthias Humt</a>,
        <strong>Jianxiang Feng</strong>,
        <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
        <br>
        International Conference on Machine Learning (ICML) 2020.
        <br>
        <a href="https://github.com/DLR-RM/curvature">code</a>
        /
        <!-- <a href="https://www.youtube.com/watch?v=vu2TnDEqDRk&t=37s&ab_channel=DLRRM">video</a>
        / -->
        <!-- <a href="https://arxiv.org/pdf/2109.12869">arXiv</a>
        / -->
        <a href="data/pmlr-v119-lee20b.bib">bibtex</a>
        <p></p>
        <p>
        A probabilistic framework to obtain both reliable and fast uncertainty estimates for predictions with Deep Neural Networks (DNNs) based on Sparse Gaussian Processes. 
        </p>
    </tr>
<! ----------------------------------------------------------------------------------------------------------------------------- -->	

<! ------------------------------------------------------- SAM ----------------------------------------------------------------- -->
<!--    <tr onmouseout="FR_SAM_stop()" onmouseover="FR_SAM_start()"  bgcolor="#ffffd0"> -->
  <tr >
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='FR_SAM_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bal_edan.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div> -->
          <img src='images/FR2023.png' width="190">
        </div>
      </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://elib.dlr.de/194517/1/Vol3_10.pdf">
        <papertitle>Virtual Reality via Object Pose Estimation and Active Learning: Realizing Telepresence Robots with Aerial Manipulation Capabilities</papertitle>
      </a>
      <br>
      <a href="https://rmc.dlr.de/rm/en/staff/jongseok.lee/">Jongseok Lee</a>, <a href="https://rmc.dlr.de/rm/en/staff/ribin.balachandran/">Ribin Radhakrishna Balachandran</a> , Konstantin Kondak, Andre Coelho, Marco De Stefano, Matthias Humt, <strong>Jianxiang Feng</strong>, Tamim Asfour,   <a href="https://rmc.dlr.de/rm/de/staff/rudolph.triebel/">Rudolph Triebel</a>,
    
      <br>
      Field Robotics
      <br>
      <a href="https://www.youtube.com/watch?v=JRnPIARW8xY&ab_channel=DLRRM">video</a>
      <!-- /
      <a href="data/bal2022.bib">bibtex</a> -->
      <p></p>
      <p>
        A novel teleoperation system for advancing aerial manipulation in dynamic and unstructured environments based on pose estimation pipelines for the industrial objects of
        both known and unknown geometries and an active learning pipeline.
      </p>
    </td>
  </tr>
  <! ------------------------------------------------------------------------------------------------------------------------ -->		
  </tbody></table>

				
	<! ------------------------------------------------------- Misc ---------------------------------------------------------- -->	
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="center">
		
	    <div class="list-item highlight" data-category="highlight">
              <p class="date">2023</p> &nbsp;&nbsp;&nbsp; Reviewer, CoRL.
            </div>
		    
	    <div class="list-item highlight" data-category="highlight">
		 <p class="date">03.2023</p> &nbsp;&nbsp;&nbsp; 1st place in the discipline assist robot race in <a href="https://cybathlon.ethz.ch/de/teams/edan">Cybathlon Challenge</a> as part of EDAN team. <a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-3755/17612_read-81519/year-2023/">press</a>
            </div>

            <div class="list-item highlight" data-category="highlight">
            <p class="date">03.2023</p> &nbsp;&nbsp;&nbsp; Master Thesis: <a href="https://elib.dlr.de/194212/">"Graph Neural Networks for Knowledge Transfer in Robotic Assembly Sequence Planning"</a> by Matan Atad, co-supervision with <a href="https://rmc.dlr.de/rm/de/staff/maximilian.durner/">Maximilian Durner</a>, <a href="https://rmc.dlr.de/rm/en/staff/ismael.rodriguezbrena/index.html">Ismael Rodriguezbrena</a>.
           </div>  
           <br>
          
            <div class="list-item highlight" data-category="highlight">
              <p class="date">2022</p> &nbsp;&nbsp;&nbsp; Reviewer, ICRA, CoRL, IROS.
            </div>
		    
          <div class="list-item highlight" data-category="highlight">
              <p class="date">06.2022</p> &nbsp;&nbsp;&nbsp; Participation in EDAN demo at Automatica Exhibition 2022 (<a href="https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-3755/17612_read-77446/year-all/17612_page-3/#/gallery/37616">press</a>).
            </div>

            <div class="list-item highlight" data-category="highlight">
              <p class="date">11.2022</p> &nbsp;&nbsp;&nbsp; Master Thesis: <a href="https://elib.dlr.de/194212/">"Scene Graph Generation from Visual perception for Task and Motion Planning"</a> by Mohit Kumar, co-supervision with <a href="https://rmc.dlr.de/rm/en/staff/samuel.bustamante/">Samuel Bustamante</a>.
            </div>  
            <br>

            <div class="list-item highlight" data-category="highlight">
            <p class="date">10.2022</p> &nbsp;&nbsp;&nbsp; Co-Organizer, IROS Workshop on <a href="https://openreview.net/group?id=IROS.org/2022/Workshop/PRDL&referrer=%5BHomepage%5D(%2F)#your-consoles">Robotics in the age of Deep Learning</a>.
            </div>
          
            <div class="list-item highlight" data-category="highlight">
              <p class="date">2020</p> &nbsp;&nbsp;&nbsp; Reviewer, ICRA, IROS, ECAI.
            </div>
              
            
            </td>
          <!-- </tr> -->
      
	<! ------------------------------------------------------------------------------------------------------------------------ -->				
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Link to the template</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <script>
        function toggle_bio() {
        var x = document.getElementById("more-bio");
        if (x.style.display === "none") {
          x.style.display = "block";
        } else {
          x.style.display = "none";
        }
      }
  </script>
</body>

</html>
